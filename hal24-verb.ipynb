{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmarks.utils import PBSSetup\n",
    "#import warnings\n",
    "#warnings.simplefilter(\"ignore\") # Silence warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = PBSSetup('hal24.yaml')\n",
    "#s = PBSSetup('setup.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read configuration yaml file here to run the benchmarks \n",
      " Creates a dask cluster using dask_jobqueue \n",
      "memory size for each node:  128gb\n",
      "number of cores for each node:  24\n",
      "number of workers for each node:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/dask_jobqueue/config.py:12: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/distributed/deploy/local.py:138: UserWarning: diagnostics_port has been deprecated. Please use `dashboard_address=` instead\n",
      "  \"diagnostics_port has been deprecated. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job script created by dask_jobqueue: starts--------\n",
      "#!/bin/bash\n",
      "\n",
      "#!/usr/bin/env bash\n",
      "#PBS -N dask-worker\n",
      "#PBS -q batch\n",
      "#PBS -l select=1:ncpus=24:mem=120GB\n",
      "#PBS -l walltime=3600\n",
      "#PBS -j oe\n",
      "JOB_ID=${PBS_JOBID%.*}\n",
      "\n",
      "OMP_NUM_THREADS=1\n",
      "\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/bin/python -m distributed.cli.dask_worker tcp://10.135.39.58:36464 --nthreads 24 --memory-limit 128.00GB --name dask-worker--${JOB_ID}-- --death-timeout 60 --local-directory $TMPDIR --nthreads 1 --interface ib0\n",
      "\n",
      "job script created by dask_jobqueue: ends --------\n",
      "dask cluster dashboard_link : \n",
      "http://10.135.39.58:8787/status\n",
      "start cluster_wait\n",
      "dask cluster client started  with 1 nodes\n",
      "client cluster \n",
      "1\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(652, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(163, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(1303, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_0931.28_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 2 nodes\n",
      "client cluster \n",
      "2\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(1303, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_0937.28_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 4 nodes\n",
      "client cluster \n",
      "4\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_0944.45_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 8 nodes\n",
      "client cluster \n",
      "8\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(41667, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 115 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(323, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_0952.30_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 16 nodes\n",
      "client cluster \n",
      "16\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(41667, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 115 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(83334, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 229 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(323, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1002.53_.csv\n",
      "client and cluster close before changing number of workers per nodes\n",
      "client cluster close finished\n",
      "client  close finished\n",
      "read configuration yaml file here to run the benchmarks \n",
      " Creates a dask cluster using dask_jobqueue \n",
      "memory size for each node:  128gb\n",
      "number of cores for each node:  24\n",
      "number of workers for each node:  1\n",
      "job script created by dask_jobqueue: starts--------\n",
      "#!/bin/bash\n",
      "\n",
      "#!/usr/bin/env bash\n",
      "#PBS -N dask-worker\n",
      "#PBS -q batch\n",
      "#PBS -l select=1:ncpus=24:mem=120GB\n",
      "#PBS -l walltime=3600\n",
      "#PBS -j oe\n",
      "JOB_ID=${PBS_JOBID%.*}\n",
      "\n",
      "OMP_NUM_THREADS=1\n",
      "\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/bin/python -m distributed.cli.dask_worker tcp://10.135.39.58:45970 --nthreads 24 --memory-limit 128.00GB --name dask-worker--${JOB_ID}-- --death-timeout 60 --local-directory $TMPDIR --nthreads 1 --interface ib0\n",
      "\n",
      "job script created by dask_jobqueue: ends --------\n",
      "dask cluster dashboard_link : \n",
      "http://10.135.39.58:8787/status\n",
      "start cluster_wait\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/distributed/deploy/local.py:138: UserWarning: diagnostics_port has been deprecated. Please use `dashboard_address=` instead\n",
      "  \"diagnostics_port has been deprecated. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask cluster client started  with 1 nodes\n",
      "client cluster \n",
      "1\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(652, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(163, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(1303, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task was destroyed but it is pending!\n",
      "task: <Task pending coro=<RequestHandler._execute() running at /home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/tornado/web.py:1699> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x2af481cf6d38>()]> cb=[_HandlerDelegate.execute.<locals>.<lambda>() at /home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/tornado/web.py:2329]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending coro=<RequestHandler._execute() running at /home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/tornado/web.py:1699> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x2af481cf6288>()]> cb=[_HandlerDelegate.execute.<locals>.<lambda>() at /home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/tornado/web.py:2329]>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1008.52_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 2 nodes\n",
      "client cluster \n",
      "2\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(1303, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1015.28_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 4 nodes\n",
      "client cluster \n",
      "4\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1022.05_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 8 nodes\n",
      "client cluster \n",
      "8\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(41667, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 115 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(323, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1029.18_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 16 nodes\n",
      "client cluster \n",
      "16\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(41667, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 115 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(83334, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 229 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(323, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1040.29_.csv\n",
      "client and cluster close before changing number of workers per nodes\n",
      "client cluster close finished\n",
      "client  close finished\n",
      "read configuration yaml file here to run the benchmarks \n",
      " Creates a dask cluster using dask_jobqueue \n",
      "memory size for each node:  128gb\n",
      "number of cores for each node:  24\n",
      "number of workers for each node:  1\n",
      "job script created by dask_jobqueue: starts--------\n",
      "#!/bin/bash\n",
      "\n",
      "#!/usr/bin/env bash\n",
      "#PBS -N dask-worker\n",
      "#PBS -q batch\n",
      "#PBS -l select=1:ncpus=24:mem=120GB\n",
      "#PBS -l walltime=3600\n",
      "#PBS -j oe\n",
      "JOB_ID=${PBS_JOBID%.*}\n",
      "\n",
      "OMP_NUM_THREADS=1\n",
      "\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/bin/python -m distributed.cli.dask_worker tcp://10.135.39.58:60023 --nthreads 24 --memory-limit 128.00GB --name dask-worker--${JOB_ID}-- --death-timeout 60 --local-directory $TMPDIR --nthreads 1 --interface ib0\n",
      "\n",
      "job script created by dask_jobqueue: ends --------\n",
      "dask cluster dashboard_link : \n",
      "http://10.135.39.58:8787/status\n",
      "start cluster_wait\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/distributed/deploy/local.py:138: UserWarning: diagnostics_port has been deprecated. Please use `dashboard_address=` instead\n",
      "  \"diagnostics_port has been deprecated. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask cluster client started  with 1 nodes\n",
      "client cluster \n",
      "1\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(652, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(163, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(1303, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1046.41_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 2 nodes\n",
      "client cluster \n",
      "2\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(1303, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1053.04_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 4 nodes\n",
      "client cluster \n",
      "4\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1059.57_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 8 nodes\n",
      "client cluster \n",
      "8\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(41667, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 115 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(323, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1107.51_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 16 nodes\n",
      "client cluster \n",
      "16\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(41667, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 115 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(83334, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 229 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(323, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1118.26_.csv\n",
      "client and cluster close before changing number of workers per nodes\n",
      "client cluster close finished\n",
      "client  close finished\n",
      "read configuration yaml file here to run the benchmarks \n",
      " Creates a dask cluster using dask_jobqueue \n",
      "memory size for each node:  128gb\n",
      "number of cores for each node:  24\n",
      "number of workers for each node:  1\n",
      "job script created by dask_jobqueue: starts--------\n",
      "#!/bin/bash\n",
      "\n",
      "#!/usr/bin/env bash\n",
      "#PBS -N dask-worker\n",
      "#PBS -q batch\n",
      "#PBS -l select=1:ncpus=24:mem=120GB\n",
      "#PBS -l walltime=3600\n",
      "#PBS -j oe\n",
      "JOB_ID=${PBS_JOBID%.*}\n",
      "\n",
      "OMP_NUM_THREADS=1\n",
      "\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/bin/python -m distributed.cli.dask_worker tcp://10.135.39.58:57487 --nthreads 24 --memory-limit 128.00GB --name dask-worker--${JOB_ID}-- --death-timeout 60 --local-directory $TMPDIR --nthreads 1 --interface ib0\n",
      "\n",
      "job script created by dask_jobqueue: ends --------\n",
      "dask cluster dashboard_link : \n",
      "http://10.135.39.58:8787/status\n",
      "start cluster_wait\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/distributed/deploy/local.py:138: UserWarning: diagnostics_port has been deprecated. Please use `dashboard_address=` instead\n",
      "  \"diagnostics_port has been deprecated. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask cluster client started  with 1 nodes\n",
      "client cluster \n",
      "1\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(652, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(163, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(1303, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task was destroyed but it is pending!\n",
      "task: <Task pending coro=<RequestHandler._execute() running at /home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/tornado/web.py:1699> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x2af49f2b40d8>()]> cb=[_HandlerDelegate.execute.<locals>.<lambda>() at /home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/tornado/web.py:2329]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending coro=<RequestHandler._execute() running at /home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/tornado/web.py:1699> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x2af49f2b4708>()]> cb=[_HandlerDelegate.execute.<locals>.<lambda>() at /home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/tornado/web.py:2329]>\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending coro=<RequestHandler._execute() running at /home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/tornado/web.py:1699> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x2af49f2b42b8>()]> cb=[_HandlerDelegate.execute.<locals>.<lambda>() at /home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/tornado/web.py:2329]>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1125.47_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 2 nodes\n",
      "client cluster \n",
      "2\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(1303, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1133.19_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 4 nodes\n",
      "client cluster \n",
      "4\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1140.40_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 8 nodes\n",
      "client cluster \n",
      "8\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(41667, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 115 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(323, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1148.40_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 16 nodes\n",
      "client cluster \n",
      "16\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(41667, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 115 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(83334, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 229 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(323, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1159.42_.csv\n",
      "client and cluster close before changing number of workers per nodes\n",
      "client cluster close finished\n",
      "client  close finished\n",
      "read configuration yaml file here to run the benchmarks \n",
      " Creates a dask cluster using dask_jobqueue \n",
      "memory size for each node:  128gb\n",
      "number of cores for each node:  24\n",
      "number of workers for each node:  1\n",
      "job script created by dask_jobqueue: starts--------\n",
      "#!/bin/bash\n",
      "\n",
      "#!/usr/bin/env bash\n",
      "#PBS -N dask-worker\n",
      "#PBS -q batch\n",
      "#PBS -l select=1:ncpus=24:mem=120GB\n",
      "#PBS -l walltime=3600\n",
      "#PBS -j oe\n",
      "JOB_ID=${PBS_JOBID%.*}\n",
      "\n",
      "OMP_NUM_THREADS=1\n",
      "\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/bin/python -m distributed.cli.dask_worker tcp://10.135.39.58:36606 --nthreads 24 --memory-limit 128.00GB --name dask-worker--${JOB_ID}-- --death-timeout 60 --local-directory $TMPDIR --nthreads 1 --interface ib0\n",
      "\n",
      "job script created by dask_jobqueue: ends --------\n",
      "dask cluster dashboard_link : \n",
      "http://10.135.39.58:8787/status\n",
      "start cluster_wait\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/distributed/deploy/local.py:138: UserWarning: diagnostics_port has been deprecated. Please use `dashboard_address=` instead\n",
      "  \"diagnostics_port has been deprecated. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask cluster client started  with 1 nodes\n",
      "client cluster \n",
      "1\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(652, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(163, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(1303, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1205.20_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 2 nodes\n",
      "client cluster \n",
      "2\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(1303, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1211.35_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 4 nodes\n",
      "client cluster \n",
      "4\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1219.06_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 8 nodes\n",
      "client cluster \n",
      "8\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(41667, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 115 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(323, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1227.06_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 16 nodes\n",
      "client cluster \n",
      "16\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(41667, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 115 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(83334, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 229 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(323, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1237.29_.csv\n",
      "client and cluster close before changing number of workers per nodes\n",
      "client cluster close finished\n",
      "client  close finished\n",
      "read configuration yaml file here to run the benchmarks \n",
      " Creates a dask cluster using dask_jobqueue \n",
      "memory size for each node:  128gb\n",
      "number of cores for each node:  24\n",
      "number of workers for each node:  1\n",
      "job script created by dask_jobqueue: starts--------\n",
      "#!/bin/bash\n",
      "\n",
      "#!/usr/bin/env bash\n",
      "#PBS -N dask-worker\n",
      "#PBS -q batch\n",
      "#PBS -l select=1:ncpus=24:mem=120GB\n",
      "#PBS -l walltime=3600\n",
      "#PBS -j oe\n",
      "JOB_ID=${PBS_JOBID%.*}\n",
      "\n",
      "OMP_NUM_THREADS=1\n",
      "\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/bin/python -m distributed.cli.dask_worker tcp://10.135.39.58:49926 --nthreads 24 --memory-limit 128.00GB --name dask-worker--${JOB_ID}-- --death-timeout 60 --local-directory $TMPDIR --nthreads 1 --interface ib0\n",
      "\n",
      "job script created by dask_jobqueue: ends --------\n",
      "dask cluster dashboard_link : \n",
      "http://10.135.39.58:8787/status\n",
      "start cluster_wait\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/distributed/deploy/local.py:138: UserWarning: diagnostics_port has been deprecated. Please use `dashboard_address=` instead\n",
      "  \"diagnostics_port has been deprecated. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask cluster client started  with 1 nodes\n",
      "client cluster \n",
      "1\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(652, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(163, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(1303, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1243.28_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 2 nodes\n",
      "client cluster \n",
      "2\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(1303, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1249.30_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 4 nodes\n",
      "client cluster \n",
      "4\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1256.00_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 8 nodes\n",
      "client cluster \n",
      "8\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(41667, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 115 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(323, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1303.15_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 16 nodes\n",
      "client cluster \n",
      "16\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(41667, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 115 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(83334, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 229 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(323, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1313.47_.csv\n",
      "client and cluster close before changing number of workers per nodes\n",
      "client cluster close finished\n",
      "client  close finished\n",
      "read configuration yaml file here to run the benchmarks \n",
      " Creates a dask cluster using dask_jobqueue \n",
      "memory size for each node:  128gb\n",
      "number of cores for each node:  24\n",
      "number of workers for each node:  1\n",
      "job script created by dask_jobqueue: starts--------\n",
      "#!/bin/bash\n",
      "\n",
      "#!/usr/bin/env bash\n",
      "#PBS -N dask-worker\n",
      "#PBS -q batch\n",
      "#PBS -l select=1:ncpus=24:mem=120GB\n",
      "#PBS -l walltime=3600\n",
      "#PBS -j oe\n",
      "JOB_ID=${PBS_JOBID%.*}\n",
      "\n",
      "OMP_NUM_THREADS=1\n",
      "\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/bin/python -m distributed.cli.dask_worker tcp://10.135.39.58:43897 --nthreads 24 --memory-limit 128.00GB --name dask-worker--${JOB_ID}-- --death-timeout 60 --local-directory $TMPDIR --nthreads 1 --interface ib0\n",
      "\n",
      "job script created by dask_jobqueue: ends --------\n",
      "dask cluster dashboard_link : \n",
      "http://10.135.39.58:8787/status\n",
      "start cluster_wait\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/distributed/deploy/local.py:138: UserWarning: diagnostics_port has been deprecated. Please use `dashboard_address=` instead\n",
      "  \"diagnostics_port has been deprecated. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask cluster client started  with 1 nodes\n",
      "client cluster \n",
      "1\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(652, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(163, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(1303, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1319.42_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 2 nodes\n",
      "client cluster \n",
      "2\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(1303, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1325.43_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 4 nodes\n",
      "client cluster \n",
      "4\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1332.24_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 8 nodes\n",
      "client cluster \n",
      "8\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(41667, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 115 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(323, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1339.46_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 16 nodes\n",
      "client cluster \n",
      "16\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(41667, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 115 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(83334, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 229 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(323, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1350.39_.csv\n",
      "client and cluster close before changing number of workers per nodes\n",
      "client cluster close finished\n",
      "client  close finished\n",
      "read configuration yaml file here to run the benchmarks \n",
      " Creates a dask cluster using dask_jobqueue \n",
      "memory size for each node:  128gb\n",
      "number of cores for each node:  24\n",
      "number of workers for each node:  1\n",
      "job script created by dask_jobqueue: starts--------\n",
      "#!/bin/bash\n",
      "\n",
      "#!/usr/bin/env bash\n",
      "#PBS -N dask-worker\n",
      "#PBS -q batch\n",
      "#PBS -l select=1:ncpus=24:mem=120GB\n",
      "#PBS -l walltime=3600\n",
      "#PBS -j oe\n",
      "JOB_ID=${PBS_JOBID%.*}\n",
      "\n",
      "OMP_NUM_THREADS=1\n",
      "\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/bin/python -m distributed.cli.dask_worker tcp://10.135.39.58:33915 --nthreads 24 --memory-limit 128.00GB --name dask-worker--${JOB_ID}-- --death-timeout 60 --local-directory $TMPDIR --nthreads 1 --interface ib0\n",
      "\n",
      "job script created by dask_jobqueue: ends --------\n",
      "dask cluster dashboard_link : \n",
      "http://10.135.39.58:8787/status\n",
      "start cluster_wait\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/distributed/deploy/local.py:138: UserWarning: diagnostics_port has been deprecated. Please use `dashboard_address=` instead\n",
      "  \"diagnostics_port has been deprecated. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask cluster client started  with 1 nodes\n",
      "client cluster \n",
      "1\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(652, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(163, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(1303, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1356.40_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 2 nodes\n",
      "client cluster \n",
      "2\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(1303, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1402.47_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 4 nodes\n",
      "client cluster \n",
      "4\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1409.27_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 8 nodes\n",
      "client cluster \n",
      "8\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(41667, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 115 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(323, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1417.08_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 16 nodes\n",
      "client cluster \n",
      "16\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(41667, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 115 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(83334, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 229 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(323, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1427.20_.csv\n",
      "client and cluster close before changing number of workers per nodes\n",
      "client cluster close finished\n",
      "client  close finished\n",
      "read configuration yaml file here to run the benchmarks \n",
      " Creates a dask cluster using dask_jobqueue \n",
      "memory size for each node:  128gb\n",
      "number of cores for each node:  24\n",
      "number of workers for each node:  1\n",
      "job script created by dask_jobqueue: starts--------\n",
      "#!/bin/bash\n",
      "\n",
      "#!/usr/bin/env bash\n",
      "#PBS -N dask-worker\n",
      "#PBS -q batch\n",
      "#PBS -l select=1:ncpus=24:mem=120GB\n",
      "#PBS -l walltime=3600\n",
      "#PBS -j oe\n",
      "JOB_ID=${PBS_JOBID%.*}\n",
      "\n",
      "OMP_NUM_THREADS=1\n",
      "\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/bin/python -m distributed.cli.dask_worker tcp://10.135.39.58:38727 --nthreads 24 --memory-limit 128.00GB --name dask-worker--${JOB_ID}-- --death-timeout 60 --local-directory $TMPDIR --nthreads 1 --interface ib0\n",
      "\n",
      "job script created by dask_jobqueue: ends --------\n",
      "dask cluster dashboard_link : \n",
      "http://10.135.39.58:8787/status\n",
      "start cluster_wait\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/distributed/deploy/local.py:138: UserWarning: diagnostics_port has been deprecated. Please use `dashboard_address=` instead\n",
      "  \"diagnostics_port has been deprecated. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask cluster client started  with 1 nodes\n",
      "client cluster \n",
      "1\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(652, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(163, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(1303, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task was destroyed but it is pending!\n",
      "task: <Task pending coro=<TCPClient.connect() running at /home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/tornado/tcpclient.py:280> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x2af471aa46d8>()]> cb=[IOLoop.add_future.<locals>.<lambda>() at /home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/tornado/ioloop.py:690]>\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1433.03_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 2 nodes\n",
      "client cluster \n",
      "2\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(1303, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1438.53_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 4 nodes\n",
      "client cluster \n",
      "4\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1445.19_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 8 nodes\n",
      "client cluster \n",
      "8\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(41667, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 115 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(323, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1454.03_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 16 nodes\n",
      "client cluster \n",
      "16\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(41667, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 115 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(83334, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 229 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(323, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1505.46_.csv\n",
      "client and cluster close before changing number of workers per nodes\n",
      "client cluster close finished\n",
      "client  close finished\n",
      "read configuration yaml file here to run the benchmarks \n",
      " Creates a dask cluster using dask_jobqueue \n",
      "memory size for each node:  128gb\n",
      "number of cores for each node:  24\n",
      "number of workers for each node:  1\n",
      "job script created by dask_jobqueue: starts--------\n",
      "#!/bin/bash\n",
      "\n",
      "#!/usr/bin/env bash\n",
      "#PBS -N dask-worker\n",
      "#PBS -q batch\n",
      "#PBS -l select=1:ncpus=24:mem=120GB\n",
      "#PBS -l walltime=3600\n",
      "#PBS -j oe\n",
      "JOB_ID=${PBS_JOBID%.*}\n",
      "\n",
      "OMP_NUM_THREADS=1\n",
      "\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/bin/python -m distributed.cli.dask_worker tcp://10.135.39.58:34506 --nthreads 24 --memory-limit 128.00GB --name dask-worker--${JOB_ID}-- --death-timeout 60 --local-directory $TMPDIR --nthreads 1 --interface ib0\n",
      "\n",
      "job script created by dask_jobqueue: ends --------\n",
      "dask cluster dashboard_link : \n",
      "http://10.135.39.58:8787/status\n",
      "start cluster_wait\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/distributed/deploy/local.py:138: UserWarning: diagnostics_port has been deprecated. Please use `dashboard_address=` instead\n",
      "  \"diagnostics_port has been deprecated. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask cluster client started  with 1 nodes\n",
      "client cluster \n",
      "1\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(652, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 652)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1981-10-13\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(652, 384, 320), chunksize=(163, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 0.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(1303, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 111, 111)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=1, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1511.32_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 2 nodes\n",
      "client cluster \n",
      "2\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(1303, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 1303)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1983-07-26\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(1303, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 1.3 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 79, 79)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=2, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1517.29_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 4 nodes\n",
      "client cluster \n",
      "4\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(2605, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 2605)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1987-02-17\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(2605, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 2.6 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 56, 56)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=4, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(520, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1524.07_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 8 nodes\n",
      "client cluster \n",
      "8\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(5209, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 15 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 5209)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1994-04-05\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(5209, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 5.1 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(41667, 40, 40)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 115 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=8, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(323, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1531.52_.csv\n",
      "start cluster_wait\n",
      "dask cluster client started  with 16 nodes\n",
      "client cluster \n",
      "16\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(10417, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 29 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(66, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=64MB, chunking_scheme=auto, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 10417)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2008-07-08\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(10417, 384, 320), chunksize=(199, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 10.2 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=spatial, chunk per worker=10\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(20834, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 58 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(131, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=128MB, chunking_scheme=auto, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 20834)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2037-01-14\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(20834, 384, 320), chunksize=(251, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 20.5 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=spatial, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(41667, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 115 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(261, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=256MB, chunking_scheme=auto, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 41667)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2094-01-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(41667, 384, 320), chunksize=(317, 192, 160)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 41.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=spatial, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(83334, 28, 28)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/odakat/miniconda3/envs/pangeobench/lib/python3.6/site-packages/xarray/core/indexing.py:1195: PerformanceWarning: Slicing with an out-of-order index is generating 229 times more chunks\n",
      "  return self.array[key]\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=temporal, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(521, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n",
      "kills ds and every other dependent computation\n",
      "benchmark start with: worker_per_node=1, num_nodes=16, chunk_size=512MB, chunking_scheme=auto, chunk per worker=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 320, lon: 384, time: 83334)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 1980-01-02 ... 2208-02-28\n",
      "  * lon      (lon) float64 -180.0 -179.1 -178.1 -177.2 ... 178.1 179.1 180.0\n",
      "  * lat      (lat) float64 -90.0 -89.44 -88.87 -88.31 ... 88.31 88.87 89.44 90.0\n",
      "Data variables:\n",
      "    sst      (time, lon, lat) float64 dask.array<shape=(83334, 384, 320), chunksize=(323, 384, 320)>\n",
      "Attributes:\n",
      "    history:  created for compute benchmarking\n",
      "\n",
      " datasize: 81.9 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kills ds and every other dependent computation\n",
      "create bench mark result file:  ./results-hal24-1thread-10chunk/compute_study_2019-08-22_1542.16_.csv\n",
      "client and cluster close before changing number of workers per nodes\n",
      "client cluster close finished\n",
      "client  close finished\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    s.run(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'dask-worker',\n",
       " 'cores': None,\n",
       " 'memory': None,\n",
       " 'processes': 1,\n",
       " 'interface': None,\n",
       " 'death-timeout': 60,\n",
       " 'local-directory': None,\n",
       " 'queue': None,\n",
       " 'project': None,\n",
       " 'walltime': '00:30:00',\n",
       " 'extra': [],\n",
       " 'env-extra': [],\n",
       " 'resource-spec': None,\n",
       " 'job-extra': [],\n",
       " 'log-directory': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask.config.get(\"jobqueue.pbs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangeobench",
   "language": "python",
   "name": "pangeobench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

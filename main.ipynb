{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmarks.utils import PBSSetup\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\") # Silence warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = PBSSetup('setup.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PBSCluster(cores=4, memory=109.00 GB, workers=4/4, jobs=1/1)\n",
      "https://jupyterhub.ucar.edu/ch/user/abanihi/proxy/8787/status\n",
      "worker_per_node=4, num_nodes=1, chunk_size=8MB, chunking_scheme=spatial\n",
      "worker_per_node=4, num_nodes=1, chunk_size=8MB, chunking_scheme=temporal\n",
      "worker_per_node=4, num_nodes=1, chunk_size=8MB, chunking_scheme=auto\n",
      "worker_per_node=4, num_nodes=1, chunk_size=16MB, chunking_scheme=spatial\n",
      "worker_per_node=4, num_nodes=1, chunk_size=16MB, chunking_scheme=temporal\n",
      "worker_per_node=4, num_nodes=1, chunk_size=16MB, chunking_scheme=auto\n",
      "worker_per_node=4, num_nodes=1, chunk_size=32MB, chunking_scheme=spatial\n",
      "worker_per_node=4, num_nodes=1, chunk_size=32MB, chunking_scheme=temporal\n",
      "worker_per_node=4, num_nodes=1, chunk_size=32MB, chunking_scheme=auto\n",
      "worker_per_node=4, num_nodes=1, chunk_size=64MB, chunking_scheme=spatial\n",
      "worker_per_node=4, num_nodes=1, chunk_size=64MB, chunking_scheme=temporal\n",
      "worker_per_node=4, num_nodes=1, chunk_size=64MB, chunking_scheme=auto\n",
      "worker_per_node=4, num_nodes=1, chunk_size=128MB, chunking_scheme=spatial\n",
      "worker_per_node=4, num_nodes=1, chunk_size=128MB, chunking_scheme=temporal\n",
      "worker_per_node=4, num_nodes=1, chunk_size=128MB, chunking_scheme=auto\n",
      "worker_per_node=4, num_nodes=1, chunk_size=256MB, chunking_scheme=spatial\n",
      "worker_per_node=4, num_nodes=1, chunk_size=256MB, chunking_scheme=temporal\n",
      "worker_per_node=4, num_nodes=1, chunk_size=256MB, chunking_scheme=auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Worker tcp://10.148.9.89:47795 restart in Job 6100868. This can be due to memory issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PBSCluster(cores=8, memory=218.00 GB, workers=8/8, jobs=2/2)\n",
      "https://jupyterhub.ucar.edu/ch/user/abanihi/proxy/8787/status\n",
      "worker_per_node=4, num_nodes=2, chunk_size=8MB, chunking_scheme=spatial\n",
      "worker_per_node=4, num_nodes=2, chunk_size=8MB, chunking_scheme=temporal\n",
      "worker_per_node=4, num_nodes=2, chunk_size=8MB, chunking_scheme=auto\n",
      "worker_per_node=4, num_nodes=2, chunk_size=16MB, chunking_scheme=spatial\n",
      "worker_per_node=4, num_nodes=2, chunk_size=16MB, chunking_scheme=temporal\n",
      "worker_per_node=4, num_nodes=2, chunk_size=16MB, chunking_scheme=auto\n",
      "worker_per_node=4, num_nodes=2, chunk_size=32MB, chunking_scheme=spatial\n",
      "worker_per_node=4, num_nodes=2, chunk_size=32MB, chunking_scheme=temporal\n",
      "worker_per_node=4, num_nodes=2, chunk_size=32MB, chunking_scheme=auto\n",
      "worker_per_node=4, num_nodes=2, chunk_size=64MB, chunking_scheme=spatial\n",
      "worker_per_node=4, num_nodes=2, chunk_size=64MB, chunking_scheme=temporal\n",
      "worker_per_node=4, num_nodes=2, chunk_size=64MB, chunking_scheme=auto\n",
      "worker_per_node=4, num_nodes=2, chunk_size=128MB, chunking_scheme=spatial\n",
      "worker_per_node=4, num_nodes=2, chunk_size=128MB, chunking_scheme=temporal\n",
      "worker_per_node=4, num_nodes=2, chunk_size=128MB, chunking_scheme=auto\n",
      "worker_per_node=4, num_nodes=2, chunk_size=256MB, chunking_scheme=spatial\n",
      "worker_per_node=4, num_nodes=2, chunk_size=256MB, chunking_scheme=temporal\n",
      "worker_per_node=4, num_nodes=2, chunk_size=256MB, chunking_scheme=auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Worker tcp://10.148.9.89:48630 restart in Job 6100868. This can be due to memory issue.\n",
      "Worker tcp://10.148.9.57:56016 restart in Job 6100880. This can be due to memory issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PBSCluster(cores=16, memory=436.00 GB, workers=16/16, jobs=4/4)\n",
      "https://jupyterhub.ucar.edu/ch/user/abanihi/proxy/8787/status\n",
      "worker_per_node=4, num_nodes=4, chunk_size=8MB, chunking_scheme=spatial\n",
      "worker_per_node=4, num_nodes=4, chunk_size=8MB, chunking_scheme=temporal\n",
      "worker_per_node=4, num_nodes=4, chunk_size=8MB, chunking_scheme=auto\n",
      "worker_per_node=4, num_nodes=4, chunk_size=16MB, chunking_scheme=spatial\n",
      "worker_per_node=4, num_nodes=4, chunk_size=16MB, chunking_scheme=temporal\n",
      "worker_per_node=4, num_nodes=4, chunk_size=16MB, chunking_scheme=auto\n",
      "worker_per_node=4, num_nodes=4, chunk_size=32MB, chunking_scheme=spatial\n",
      "worker_per_node=4, num_nodes=4, chunk_size=32MB, chunking_scheme=temporal\n",
      "worker_per_node=4, num_nodes=4, chunk_size=32MB, chunking_scheme=auto\n",
      "worker_per_node=4, num_nodes=4, chunk_size=64MB, chunking_scheme=spatial\n",
      "worker_per_node=4, num_nodes=4, chunk_size=64MB, chunking_scheme=temporal\n",
      "worker_per_node=4, num_nodes=4, chunk_size=64MB, chunking_scheme=auto\n",
      "worker_per_node=4, num_nodes=4, chunk_size=128MB, chunking_scheme=spatial\n",
      "worker_per_node=4, num_nodes=4, chunk_size=128MB, chunking_scheme=temporal\n",
      "worker_per_node=4, num_nodes=4, chunk_size=128MB, chunking_scheme=auto\n",
      "worker_per_node=4, num_nodes=4, chunk_size=256MB, chunking_scheme=spatial\n",
      "worker_per_node=4, num_nodes=4, chunk_size=256MB, chunking_scheme=temporal\n",
      "worker_per_node=4, num_nodes=4, chunk_size=256MB, chunking_scheme=auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Worker tcp://10.148.9.57:45246 restart in Job 6100880. This can be due to memory issue.\n",
      "Worker tcp://10.148.10.22:35932 restart in Job 6100897. This can be due to memory issue.\n",
      "Worker tcp://10.148.9.89:54068 restart in Job 6100868. This can be due to memory issue.\n",
      "Worker tcp://10.148.10.20:49458 restart in Job 6100896. This can be due to memory issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PBSCluster(cores=32, memory=872.00 GB, workers=32/32, jobs=8/8)\n",
      "https://jupyterhub.ucar.edu/ch/user/abanihi/proxy/8787/status\n",
      "worker_per_node=4, num_nodes=8, chunk_size=8MB, chunking_scheme=spatial\n",
      "worker_per_node=4, num_nodes=8, chunk_size=8MB, chunking_scheme=temporal\n",
      "worker_per_node=4, num_nodes=8, chunk_size=8MB, chunking_scheme=auto\n",
      "worker_per_node=4, num_nodes=8, chunk_size=16MB, chunking_scheme=spatial\n",
      "worker_per_node=4, num_nodes=8, chunk_size=16MB, chunking_scheme=temporal\n",
      "worker_per_node=4, num_nodes=8, chunk_size=16MB, chunking_scheme=auto\n",
      "worker_per_node=4, num_nodes=8, chunk_size=32MB, chunking_scheme=spatial\n",
      "worker_per_node=4, num_nodes=8, chunk_size=32MB, chunking_scheme=temporal\n",
      "worker_per_node=4, num_nodes=8, chunk_size=32MB, chunking_scheme=auto\n",
      "worker_per_node=4, num_nodes=8, chunk_size=64MB, chunking_scheme=spatial\n",
      "worker_per_node=4, num_nodes=8, chunk_size=64MB, chunking_scheme=temporal\n",
      "worker_per_node=4, num_nodes=8, chunk_size=64MB, chunking_scheme=auto\n",
      "worker_per_node=4, num_nodes=8, chunk_size=128MB, chunking_scheme=spatial\n",
      "worker_per_node=4, num_nodes=8, chunk_size=128MB, chunking_scheme=temporal\n",
      "worker_per_node=4, num_nodes=8, chunk_size=128MB, chunking_scheme=auto\n",
      "worker_per_node=4, num_nodes=8, chunk_size=256MB, chunking_scheme=spatial\n",
      "worker_per_node=4, num_nodes=8, chunk_size=256MB, chunking_scheme=temporal\n",
      "worker_per_node=4, num_nodes=8, chunk_size=256MB, chunking_scheme=auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Worker tcp://10.148.10.20:42820 restart in Job 6100896. This can be due to memory issue.\n",
      "Worker tcp://10.148.9.57:38459 restart in Job 6100880. This can be due to memory issue.\n",
      "Worker tcp://10.148.10.22:42622 restart in Job 6100897. This can be due to memory issue.\n",
      "Worker tcp://10.148.9.114:52579 restart in Job 6100968. This can be due to memory issue.\n",
      "Worker tcp://10.148.9.112:44405 restart in Job 6100967. This can be due to memory issue.\n",
      "Worker tcp://10.148.9.33:55416 restart in Job 6100965. This can be due to memory issue.\n",
      "Worker tcp://10.148.9.89:58857 restart in Job 6100868. This can be due to memory issue.\n",
      "Worker tcp://10.148.9.116:37232 restart in Job 6100969. This can be due to memory issue.\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://10.148.10.21:40762 remote=tcp://10.148.10.21:49981>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://10.148.10.21:40815 remote=tcp://10.148.10.21:49981>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://10.148.10.21:41017 remote=tcp://10.148.10.21:49981>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://10.148.10.21:41407 remote=tcp://10.148.10.21:49981>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://10.148.10.21:41409 remote=tcp://10.148.10.21:49981>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PBSCluster(cores=8, memory=109.00 GB, workers=8/8, jobs=1/1)\n",
      "https://jupyterhub.ucar.edu/ch/user/abanihi/proxy/8787/status\n",
      "worker_per_node=8, num_nodes=1, chunk_size=8MB, chunking_scheme=spatial\n",
      "worker_per_node=8, num_nodes=1, chunk_size=8MB, chunking_scheme=temporal\n",
      "worker_per_node=8, num_nodes=1, chunk_size=8MB, chunking_scheme=auto\n",
      "worker_per_node=8, num_nodes=1, chunk_size=16MB, chunking_scheme=spatial\n",
      "worker_per_node=8, num_nodes=1, chunk_size=16MB, chunking_scheme=temporal\n",
      "worker_per_node=8, num_nodes=1, chunk_size=16MB, chunking_scheme=auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "Exception ignored in: <generator object Scheduler.add_client at 0x2aaac9f099a8>\n",
      "RuntimeError: generator ignored GeneratorExit\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "Future exception was never retrieved\n",
      "future: <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 181, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 201, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/distributed/comm/tcp.py\", line 130, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker_per_node=8, num_nodes=1, chunk_size=32MB, chunking_scheme=spatial\n",
      "worker_per_node=8, num_nodes=1, chunk_size=32MB, chunking_scheme=temporal\n",
      "worker_per_node=8, num_nodes=1, chunk_size=32MB, chunking_scheme=auto\n",
      "worker_per_node=8, num_nodes=1, chunk_size=64MB, chunking_scheme=spatial\n",
      "worker_per_node=8, num_nodes=1, chunk_size=64MB, chunking_scheme=temporal\n",
      "worker_per_node=8, num_nodes=1, chunk_size=64MB, chunking_scheme=auto\n",
      "worker_per_node=8, num_nodes=1, chunk_size=128MB, chunking_scheme=spatial\n",
      "worker_per_node=8, num_nodes=1, chunk_size=128MB, chunking_scheme=temporal\n",
      "worker_per_node=8, num_nodes=1, chunk_size=128MB, chunking_scheme=auto\n",
      "worker_per_node=8, num_nodes=1, chunk_size=256MB, chunking_scheme=spatial\n",
      "worker_per_node=8, num_nodes=1, chunk_size=256MB, chunking_scheme=temporal\n",
      "worker_per_node=8, num_nodes=1, chunk_size=256MB, chunking_scheme=auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Worker tcp://10.148.9.33:60081 restart in Job 6101017. This can be due to memory issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PBSCluster(cores=16, memory=218.00 GB, workers=16/16, jobs=2/2)\n",
      "https://jupyterhub.ucar.edu/ch/user/abanihi/proxy/8787/status\n",
      "worker_per_node=8, num_nodes=2, chunk_size=8MB, chunking_scheme=spatial\n",
      "worker_per_node=8, num_nodes=2, chunk_size=8MB, chunking_scheme=temporal\n",
      "worker_per_node=8, num_nodes=2, chunk_size=8MB, chunking_scheme=auto\n",
      "worker_per_node=8, num_nodes=2, chunk_size=16MB, chunking_scheme=spatial\n",
      "worker_per_node=8, num_nodes=2, chunk_size=16MB, chunking_scheme=temporal\n",
      "worker_per_node=8, num_nodes=2, chunk_size=16MB, chunking_scheme=auto\n",
      "worker_per_node=8, num_nodes=2, chunk_size=32MB, chunking_scheme=spatial\n",
      "worker_per_node=8, num_nodes=2, chunk_size=32MB, chunking_scheme=temporal\n",
      "worker_per_node=8, num_nodes=2, chunk_size=32MB, chunking_scheme=auto\n",
      "worker_per_node=8, num_nodes=2, chunk_size=64MB, chunking_scheme=spatial\n",
      "worker_per_node=8, num_nodes=2, chunk_size=64MB, chunking_scheme=temporal\n",
      "worker_per_node=8, num_nodes=2, chunk_size=64MB, chunking_scheme=auto\n",
      "worker_per_node=8, num_nodes=2, chunk_size=128MB, chunking_scheme=spatial\n",
      "worker_per_node=8, num_nodes=2, chunk_size=128MB, chunking_scheme=temporal\n",
      "worker_per_node=8, num_nodes=2, chunk_size=128MB, chunking_scheme=auto\n",
      "worker_per_node=8, num_nodes=2, chunk_size=256MB, chunking_scheme=spatial\n",
      "worker_per_node=8, num_nodes=2, chunk_size=256MB, chunking_scheme=temporal\n",
      "worker_per_node=8, num_nodes=2, chunk_size=256MB, chunking_scheme=auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Worker tcp://10.148.9.31:51424 restart in Job 6101131. This can be due to memory issue.\n",
      "Worker tcp://10.148.9.33:54922 restart in Job 6101017. This can be due to memory issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PBSCluster(cores=32, memory=436.00 GB, workers=32/32, jobs=4/4)\n",
      "https://jupyterhub.ucar.edu/ch/user/abanihi/proxy/8787/status\n",
      "worker_per_node=8, num_nodes=4, chunk_size=8MB, chunking_scheme=spatial\n",
      "worker_per_node=8, num_nodes=4, chunk_size=8MB, chunking_scheme=temporal\n",
      "worker_per_node=8, num_nodes=4, chunk_size=8MB, chunking_scheme=auto\n",
      "worker_per_node=8, num_nodes=4, chunk_size=16MB, chunking_scheme=spatial\n",
      "worker_per_node=8, num_nodes=4, chunk_size=16MB, chunking_scheme=temporal\n",
      "worker_per_node=8, num_nodes=4, chunk_size=16MB, chunking_scheme=auto\n",
      "worker_per_node=8, num_nodes=4, chunk_size=32MB, chunking_scheme=spatial\n",
      "worker_per_node=8, num_nodes=4, chunk_size=32MB, chunking_scheme=temporal\n",
      "worker_per_node=8, num_nodes=4, chunk_size=32MB, chunking_scheme=auto\n",
      "worker_per_node=8, num_nodes=4, chunk_size=64MB, chunking_scheme=spatial\n",
      "worker_per_node=8, num_nodes=4, chunk_size=64MB, chunking_scheme=temporal\n",
      "worker_per_node=8, num_nodes=4, chunk_size=64MB, chunking_scheme=auto\n",
      "worker_per_node=8, num_nodes=4, chunk_size=128MB, chunking_scheme=spatial\n",
      "worker_per_node=8, num_nodes=4, chunk_size=128MB, chunking_scheme=temporal\n",
      "worker_per_node=8, num_nodes=4, chunk_size=128MB, chunking_scheme=auto\n",
      "worker_per_node=8, num_nodes=4, chunk_size=256MB, chunking_scheme=spatial\n",
      "worker_per_node=8, num_nodes=4, chunk_size=256MB, chunking_scheme=temporal\n",
      "worker_per_node=8, num_nodes=4, chunk_size=256MB, chunking_scheme=auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Worker tcp://10.148.9.31:38908 restart in Job 6101131. This can be due to memory issue.\n",
      "Worker tcp://10.148.9.33:36378 restart in Job 6101017. This can be due to memory issue.\n",
      "Worker tcp://10.148.11.89:36142 restart in Job 6101155. This can be due to memory issue.\n",
      "Worker tcp://10.148.6.253:58917 restart in Job 6101156. This can be due to memory issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PBSCluster(cores=64, memory=872.00 GB, workers=64/64, jobs=8/8)\n",
      "https://jupyterhub.ucar.edu/ch/user/abanihi/proxy/8787/status\n",
      "worker_per_node=8, num_nodes=8, chunk_size=8MB, chunking_scheme=spatial\n",
      "worker_per_node=8, num_nodes=8, chunk_size=8MB, chunking_scheme=temporal\n",
      "worker_per_node=8, num_nodes=8, chunk_size=8MB, chunking_scheme=auto\n",
      "worker_per_node=8, num_nodes=8, chunk_size=16MB, chunking_scheme=spatial\n",
      "worker_per_node=8, num_nodes=8, chunk_size=16MB, chunking_scheme=temporal\n",
      "worker_per_node=8, num_nodes=8, chunk_size=16MB, chunking_scheme=auto\n",
      "worker_per_node=8, num_nodes=8, chunk_size=32MB, chunking_scheme=spatial\n",
      "worker_per_node=8, num_nodes=8, chunk_size=32MB, chunking_scheme=temporal\n",
      "worker_per_node=8, num_nodes=8, chunk_size=32MB, chunking_scheme=auto\n",
      "worker_per_node=8, num_nodes=8, chunk_size=64MB, chunking_scheme=spatial\n",
      "worker_per_node=8, num_nodes=8, chunk_size=64MB, chunking_scheme=temporal\n",
      "worker_per_node=8, num_nodes=8, chunk_size=64MB, chunking_scheme=auto\n",
      "worker_per_node=8, num_nodes=8, chunk_size=128MB, chunking_scheme=spatial\n",
      "worker_per_node=8, num_nodes=8, chunk_size=128MB, chunking_scheme=temporal\n",
      "worker_per_node=8, num_nodes=8, chunk_size=128MB, chunking_scheme=auto\n",
      "worker_per_node=8, num_nodes=8, chunk_size=256MB, chunking_scheme=spatial\n",
      "worker_per_node=8, num_nodes=8, chunk_size=256MB, chunking_scheme=temporal\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d7602d626a94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#for i in range(3):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/gpfs/fs1/work/abanihi/devel/pangeo/benchmarking/benchmarks/utils.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    108\u001b[0m                                 \u001b[0mmachine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmachine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                             ):\n\u001b[0;32m--> 110\u001b[0;31m                                 \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# kills ds, and every other dependent computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    634\u001b[0m         \"\"\"\n\u001b[1;32m    635\u001b[0m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_persist_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0;31m# evaluate all the dask arrays simultaneously\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m             \u001b[0mevaluated_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlazy_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlazy_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluated_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0mpostcomputes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/dask/base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0mpostcomputes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/dask/array/core.py\u001b[0m in \u001b[0;36mfinalize\u001b[0;34m(results)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mresults2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/abanihi/softwares/miniconda3/envs/analysis/lib/python3.7/site-packages/dask/array/core.py\u001b[0m in \u001b[0;36mconcatenate3\u001b[0;34m(arrays)\u001b[0m\n\u001b[1;32m   3525\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3527\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3529\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslices_from_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#for i in range(3):\n",
    "s.run(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.client.cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.client.cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis]",
   "language": "python",
   "name": "conda-env-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
